{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e950b8d",
   "metadata": {},
   "source": [
    "# Transcription factor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb494b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "from nn import nn, io, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b83361",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debde312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rap1 positives: 137\n",
      "Length of Yeast negatives: 3163\n"
     ]
    }
   ],
   "source": [
    "rap1 = io.read_text_file(\"./data/rap1-lieb-positives.txt\")\n",
    "yeast = io.read_fasta_file(\"./data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "print(\"Length of Rap1 positives: \" + str(len(rap1)))\n",
    "print(\"Length of Yeast negatives: \" + str(len(yeast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cc89b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of positives: 137\n",
      "Length of negatives: 183297\n",
      "Total sequences: 183434\n"
     ]
    }
   ],
   "source": [
    "pos_seq = rap1\n",
    "\n",
    "# Break up yeast_neg into sizes match the length of rap1 sequences\n",
    "seq_len = len(rap1[0])\n",
    "neg_seq = []\n",
    "\n",
    "for seq in yeast:\n",
    "    seq_sub = [seq[i:i+seq_len] for i in range(0, len(seq), seq_len)]\n",
    "    # Keep only sequences that are exactly rap length long\n",
    "    seq_sub = [x for x in seq_sub if len(x) == seq_len]\n",
    "    neg_seq += seq_sub\n",
    "\n",
    "# Combine all sequences and get labes\n",
    "seqs = pos_seq + neg_seq\n",
    "labels = [True] * len(pos_seq) + [False] * len(neg_seq)\n",
    "\n",
    "print(\"Length of positives: \" + str(len(pos_seq)))\n",
    "print(\"Length of negatives: \" + str(len(neg_seq)))\n",
    "print(\"Total sequences: \" + str(len(pos_seq) + len(neg_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda8e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of positives: 183297\n",
      "Length of negatives: 183297\n",
      "Total sequences: 366594\n"
     ]
    }
   ],
   "source": [
    "# Up sample the positive class\n",
    "seqs2, labels2 = preprocess.sample_seqs(seqs, labels)\n",
    "print(\"Length of positives: \" + str(sum(labels2)))\n",
    "print(\"Length of negatives: \" + str(len(seqs2) - sum(labels2)))\n",
    "print(\"Total sequences: \" + str(len(seqs2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc62ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (256615, 68)\n",
      "Testing data (109979, 68)\n"
     ]
    }
   ],
   "source": [
    "# Encode sequences and create a training and testing split\n",
    "X = preprocess.one_hot_encode_seqs(seqs2)\n",
    "y = np.array(labels2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "print(\"Training data \" + str(X_train.shape))\n",
    "print(\"Testing data \" + str(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f74cc51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward:\n",
      "Layer index: 1\n",
      "Shape _W :(40, 68)\n",
      "Shape _b :(40, 1)\n",
      "Shape _A_prev: (20, 68)\n",
      "Shape Z_curr :(20, 40)\n",
      "Shape A_curr: (20, 40)\n",
      "Layer index: 2\n",
      "Shape _W :(20, 40)\n",
      "Shape _b :(20, 1)\n",
      "Shape _A_prev: (20, 40)\n",
      "Shape Z_curr :(20, 20)\n",
      "Shape A_curr: (20, 20)\n",
      "Layer index: 3\n",
      "Shape _W :(1, 20)\n",
      "Shape _b :(1, 1)\n",
      "Shape _A_prev: (20, 20)\n",
      "Shape Z_curr :(20, 1)\n",
      "Shape A_curr: (20, 1)\n",
      "Backprop\n",
      "Shape _y_batch (y): (20,)\n",
      "Shape output (y_hat): (20, 1)\n",
      "_BCE_BP dA shape: (20, 20)\n",
      "Layer index: 3\n",
      "Shape _W_curr :(1, 20)\n",
      "Shape _b_curr :(1, 1)\n",
      "Shape _Z_curr: (20, 1)\n",
      "Shape _A_prev:(20, 20)\n",
      "Shape _dA: (20, 20)\n",
      "Shape bp: (20, 20)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (20,20) and (1,20) not aligned: 20 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m layers \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m68\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m40\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m40\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m      5\u001b[0m net \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNeuralNetwork(layers, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, loss_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Box-Box/BMI203/Github/FINAL-NN/nn/nn.py:376\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape _y_batch (y): \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(_y_batch\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape output (y_hat): \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m--> 376\u001b[0m grad_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_y_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_params(grad_dict)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Calculate average training loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Box-Box/BMI203/Github/FINAL-NN/nn/nn.py:277\u001b[0m, in \u001b[0;36mNeuralNetwork.backprop\u001b[0;34m(self, y, y_hat, cache)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape _dA: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(_dA_curr\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Run single backprop\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m dA_prev, dW_curr, db_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_backprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_curr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_W_curr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mb_curr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_b_curr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mZ_curr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_Z_curr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mA_prev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_A_prev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mdA_curr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_dA_curr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mactivation_curr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_activation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Populate grad_dict with results from single backprop\u001b[39;00m\n\u001b[1;32m    285\u001b[0m grad_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(layer_idx)] \u001b[38;5;241m=\u001b[39m dW_curr\n",
      "File \u001b[0;32m~/Library/CloudStorage/Box-Box/BMI203/Github/FINAL-NN/nn/nn.py:220\u001b[0m, in \u001b[0;36mNeuralNetwork._single_backprop\u001b[0;34m(self, W_curr, b_curr, Z_curr, A_prev, dA_curr, activation_curr)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape bp: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(bp\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Calculate dA, dW, db\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m dA_prev \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_curr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m dW_curr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(bp\u001b[38;5;241m.\u001b[39mT, A_prev)\n\u001b[1;32m    222\u001b[0m db_curr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(bp, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (20,20) and (1,20) not aligned: 20 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Create network\n",
    "layers = [{\"input_dim\": 68, \"output_dim\": 40, \"activation\": \"sigmoid\"},\n",
    "          {\"input_dim\": 40, \"output_dim\": 20, \"activation\": \"sigmoid\"},\n",
    "          {\"input_dim\": 20, \"output_dim\": 1, \"activation\": \"sigmoid\"}]\n",
    "net = nn.NeuralNetwork(layers, lr = 0.0001, seed = 1, batch_size = 20, epochs = 1, loss_function = \"bce\")\n",
    "\n",
    "train_loss, val_loss = net.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07aff274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0(20, 68)\n",
      "A1(20, 40)\n",
      "Z1(20, 40)\n",
      "A2(20, 20)\n",
      "Z2(20, 20)\n",
      "A3(20, 1)\n",
      "Z3(20, 1)\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,4):\n",
    "    try:\n",
    "        print(\"A\" + str(idx) + str(net.cache[\"A\"+str(idx)].shape))\n",
    "        print(\"Z\" + str(idx) +str(net.cache[\"Z\"+str(idx)].shape))\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b64176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(40, 68)\n",
      "b1(40, 1)\n",
      "W2(20, 40)\n",
      "b2(20, 1)\n",
      "W3(1, 20)\n",
      "b3(1, 1)\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,4):\n",
    "    try:\n",
    "        print(\"W\" + str(idx) + str(net._param_dict[\"W\"+str(idx)].shape))\n",
    "        print(\"b\" + str(idx) +str(net._param_dict[\"b\"+str(idx)].shape))\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0b6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
